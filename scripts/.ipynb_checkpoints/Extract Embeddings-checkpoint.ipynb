{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15b23959-5024-464e-8c66-739a1469ede9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/rahulbrito/.cache/torch/hub/pyannote_pyannote-audio_master\n",
      "Using cache found in /Users/rahulbrito/.cache/torch/hub/pyannote_pyannote-audio_master\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import seed, shuffle\n",
    "import os\n",
    "\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.cluster import KMeans, SpectralClustering\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.spatial.distance import directed_hausdorff, euclidean, cosine, pdist\n",
    "\n",
    "from src.downsample import downsamp_audio\n",
    "import src.embedding_extractor as ee\n",
    "import src.dimension_reducer as dr\n",
    "import src.distance_metrics as dm\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "one_samp_toy_dir = '/Users/rahulbrito/Documents/projects/infantvoice/data/Full_Readings/one_samp_toy_downsamp' #toy dataset with one participant recording @16kHz\n",
    "#two_samp_toy_dir = '/Users/rahulbrito/Documents/projects/infantvoice/data/Full_Readings/two_samp_toy_downsamp'#toy dataset with two participant recordings @16kHz\n",
    "two_samp_toy_dir ='/Users/rahulbrito/Documents/projects/infantvoice/data/Full_Readings/020422_postpartum_moms_two_samp_toy'\n",
    "down_sampled_dir = '/Users/rahulbrito/Documents/projects/infantvoice/data/Full_Readings/downsamp'#all the data, downsampled to 16kHz\n",
    "embedding_dir = '/Users/rahulbrito/Documents/projects/infantvoice/data/embeddings' #location of embeddings save new embeddings load pre-generated ones from here\n",
    "emb_models = ['emb_ami', 'emb','emb_voxceleb'] #names of pretrained embedding extractor models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a114150c-ba21-47e6-9ffc-a049075957c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing008.wav\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "## Extracts embeddings from a directory of wav files. Can choose to save those embeddings to a .csv file (recommended because this can take a few hours on a laptop)\n",
    "\n",
    "#[ee.pyannote_extract_directory(model,down_sampled_dir,embedding_dir,'020322_embeddings_testreadings', save=True) for model in emb_models]\n",
    "[ee.pyannote_extract_directory(model,two_samp_toy_dir,embedding_dir,'', save=False) for model in emb_models]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "infantvoice",
   "language": "python",
   "name": "infantvoice"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
